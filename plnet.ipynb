{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "# import lattice_filter_op_loader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from scipy.misc import imresize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras import objectives, layers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/likewise-open/SENSETIME/qiuhaonan/Desktop/plnet/datasets/A'\n",
    "output_path = '/home/likewise-open/SENSETIME/qiuhaonan/Desktop/plnet/datasets/B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 256\n",
    "n = 256\n",
    "sketch_dim = (m,n,3)\n",
    "img_dim = (m,n,3)\n",
    "num_images = 16\n",
    "num_epochs = 2\n",
    "batch_size = 4\n",
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_names(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "def sub_plot(x,y,z):\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1,3,1)\n",
    "    imgplot = plt.imshow(x, cmap='gray')\n",
    "    a.set_title('Sketch')\n",
    "    plt.axis(\"off\")\n",
    "    a = fig.add_subplot(1,3,2)\n",
    "    imgplot = plt.imshow(z)\n",
    "    a.set_title('Prediction')\n",
    "    plt.axis(\"off\")\n",
    "    a = fig.add_subplot(1,3,3)\n",
    "    imgplot = plt.imshow(y)\n",
    "    a.set_title('Ground Truth')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def imshow(x, gray=False):\n",
    "    plt.imshow(x, cmap='gray' if gray else None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(idx, X = True, Y = True):\n",
    "    \n",
    "    global file_names\n",
    "\n",
    "    X_train = np.zeros((batch_size, m, n, 3), dtype='float32')\n",
    "    Y_train = np.zeros((batch_size, m, n, 3), dtype='float32')\n",
    "    F_train = None\n",
    "    \n",
    "    x_path = input_path\n",
    "    y_path = output_path\n",
    "    \n",
    "    if len(file_names) == 0:\n",
    "        file_names = load_file_names(x_path)\n",
    "        \n",
    "    if X:\n",
    "        # Load Sketches\n",
    "        for i in range(batch_size):\n",
    "            file = os.path.join(x_path, file_names[i+batch_size*idx])\n",
    "            img = cv2.imread(file)\n",
    "            img = imresize(img, sketch_dim)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype('float32')\n",
    "            X_train[i] = img / 255.\n",
    "            \n",
    "    if Y:\n",
    "        # Load Ground-truth Images\n",
    "        for i in range(batch_size):\n",
    "            file = os.path.join(y_path, file_names[i+batch_size*idx])\n",
    "            img = cv2.imread(file)\n",
    "            img = imresize(img, img_dim)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype('float32')\n",
    "            Y_train[i] = img / 255.\n",
    "    \n",
    "    X_train = np.reshape(X_train, (batch_size, m, n, 3))\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred))) + 0.00001*total_variation_loss(y_pred)\n",
    "\n",
    "def total_variation_loss(y_pred):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(y_pred[:, :, :m - 1, :n - 1] - y_pred[:, :, 1:, :n - 1])\n",
    "        b = K.square(y_pred[:, :, :m - 1, :n - 1] - y_pred[:, :, :m - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(y_pred[:, :m - 1, :n - 1, :] - y_pred[:, 1:, :n - 1, :])\n",
    "        b = K.square(y_pred[:, :m - 1, :n - 1, :] - y_pred[:, :m - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(input_img):\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(3, (3, 3), activation=None, padding='same')(x)\n",
    "#     output = module.lattice_filter(x, reference_image, bilateral=True, theta_alpha=8, theta_beta=0.125)\n",
    "    return x\n",
    "\n",
    "def full_model(summary = True):\n",
    "    input_img = Input(shape=(m, n, 3))\n",
    "    generator = generator_model(input_img)\n",
    "    model = Model(input=input_img, output=[generator], name='architect')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_faces(weights=None):\n",
    "\n",
    "    model = full_model()\n",
    "    optim = Adam(lr=1e-4,beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(loss=[pixel_loss], loss_weights=[1], optimizer=optim)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    print('start train')\n",
    "    for epoch in range(num_epochs):\n",
    "        num_batches = num_images // batch_size\n",
    "        print('epoch:',epoch)\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            X,Y = get_batch(batch)\n",
    "            loss = model.train_on_batch(X, [Y])\n",
    "            print(\"Loss in Epoch # \",epoch,\"| Batch #\", batch, \":\", loss)\n",
    "\n",
    "        model.save_weights(\"weights_%d\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/likewise-open/SENSETIME/qiuhaonan/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"architect\", inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/likewise-open/SENSETIME/qiuhaonan/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/home/likewise-open/SENSETIME/qiuhaonan/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 3)       867       \n",
      "=================================================================\n",
      "Total params: 11,011\n",
      "Trainable params: 11,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "start train\n",
      "epoch: 0\n"
     ]
    }
   ],
   "source": [
    "def predict(batch, i, weights):\n",
    "    model = full_model()\n",
    "    model.load_weights(weights)\n",
    "    X, T = get_batch(batch, Y = True)\n",
    "    Y= model.predict(X[:i])\n",
    "    x = X[i].reshape(m,n)\n",
    "    y = Y[i]\n",
    "    sub_plot(x, T[i], y)\n",
    "\n",
    "\n",
    "def sketchback(image, weights):\n",
    "    model = full_model()\n",
    "    model.load_weights(weights)\n",
    "    sketch = cv2.imread(image)\n",
    "    sketch = imresize(sketch, sketch_dim)\n",
    "    sketch = sketch / 255.\n",
    "    sketch = sketch.reshape(1,m,n,3)\n",
    "    result = model.predict(sketch)\n",
    "    imshow(result[0])\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1,2,1)\n",
    "    imgplot = plt.imshow(sketch[0].reshape(m,n), cmap='gray')\n",
    "    a.set_title('Sketch')\n",
    "    plt.axis(\"off\")\n",
    "    a = fig.add_subplot(1,2,2)\n",
    "    imgplot = plt.imshow(result[0])\n",
    "    a.set_title('Prediction')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_faces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf36",
   "language": "python",
   "name": "tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
